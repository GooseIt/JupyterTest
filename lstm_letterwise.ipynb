{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 2968907\n",
      "Total chars: 38\n",
      "Number of sequences: 989623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-e18b09359555>:29: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "<ipython-input-2-e18b09359555>:30: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "paths = ['lstm/data/war-and-peace-1.txt', \n",
    "         'lstm/data/war-and-peace-2.txt', \n",
    "         'lstm/data/war-and-peace-34.txt']\n",
    "text_total = ''\n",
    "for path in paths:\n",
    "    with io.open(path, encoding=\"cp1251\") as f:\n",
    "        text = f.read().lower()\n",
    "    text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "    text = re.sub('[^а-я ,.!?-]', '', text) #L Leave only Russian and number and punctuation\n",
    "    text_total += text\n",
    "text = text_total\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7732/7732 [==============================] - 636s 82ms/step - loss: 1.7950\n",
      "Epoch 0 done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text after epoch: 1\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"ачальствованья.      вернувшись после вт\"\n",
      "...Generated:  орожение и в после собою и простить в перевых и после своего своего приветно и приветения и после своего пристрого под на себе подоманно и приставления к свою после собою сторон и не подомания и своего приставления и своего принять на дела и после под состояли и не подворил на после своего поднял на своего стараться на карагина и после нему на после нему и не видно от нему и после под на себе и пр\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"ачальствованья.      вернувшись после вт\"\n",
      "...Generated:  орой успев на свою на минуту не будет, - как не в перед крыльцы и своего собой, потому, что на нее.      - наташа и на движения и после несколько в предвигавших от голоса, потому когда ни вдруг и как близко и принять в перене и против и даков своего и преказа в петербург. он который он не подумала и подочно проказывал свою положаль и приготовленной положения не вы не обратилась на опомнила он обар\n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"ачальствованья.      вернувшись после вт\"\n",
      "...Generated:  еренн привогка. я нарежалась лка, как мужи с нам присютелось в воготок и вечера не потупать свое?  ну, сказала пердов артия к томи рцовенный, и не мание в зналении шесшие к своей проговорил он вдвозятно смотрило в сражения потвержал аздрмев прявами и не у такое людя и усталенно и пристройкова привым рисполкды, которым теперь перят к народнысть, млопать, порежал равных понагиная, как последного кос\n",
      "\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \"ачальствованья.      вернувшись после вт\"\n",
      "...Generated:  уры, нетскохбужов, ны жит и к нънищае, как и в привы для неголю. он ни такбе отвечаша будушно, ркиноге им вступкильга. не.  мы не принять, кутузов с мотвах отхари. нчепениной тыречно голосовов, обещания . мы жнидать о прекреил, что курандки, он ни конхийской месте продворные, которое быть. свою когда, начал, и всю был только, будто бешейцком раздать ести париба того плачик кажд, сказал он.  и, гро\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating text after epoch: %d\" % 1)\n",
    "if True:\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7732/7732 [==============================] - 645s 83ms/step - loss: 1.6113\n",
      "Epoch 1 done!\n",
      "7732/7732 [==============================] - 654s 85ms/step - loss: 1.5731\n",
      "Epoch 2 done!\n",
      "7732/7732 [==============================] - 596s 77ms/step - loss: 1.5513\n",
      "Epoch 3 done!\n",
      "7732/7732 [==============================] - 563s 73ms/step - loss: 1.5372\n",
      "Epoch 4 done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text after epoch: 5\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"ть в бурнусе в мечети, так в москве надо\"\n",
      "...Generated:   все полковника и солдата с наполеонами и после подняли с ноги и с своей полковниками и солдата в последней солдат, но не слушали полк было на крестящей самый шагали он с нем состояние с столом, наполеон и солдат расстроить и разговор с том, что он после последний солдат в середине и и с ней и солдат в котором он не спрашивал он не спрашивал с своей рассказывали и после своей собой с которой он не\n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"ть в бурнусе в мечети, так в москве надо\"\n",
      "...Generated:   хорошо и в нем возможностью собой в вольситерской глаза, и позиции случает солдат собой о том, что все представлял его с будушь войска направенно спокойное и дарами.  он получил и которое он подошла в том только наполеоных солдата строго и ты не знаюшь на то, что он не счастья и всегда же соня и после так же наполеона дороге по полк на понять от середина кротко наполеона и все полковника улыбкой \n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"ть в бурнусе в мечети, так в москве надо\"\n",
      "...Generated:   оль только неизвестно, я по бы ехали. уже виселененное и заступки, когда совершенная, и напранулась только прошине. кити, по ней солдаты проходить искупинных, денисова и в тотю, маленькие, донисти подтомата и, так, что он суд опыт кязание шечания, я на статании, надевать он его только ее добра и за вторый состояния ее армиды, валетствующие виновать! что я взгляняя и отдавкивая это со в жении свои\n",
      "\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \"ть в бурнусе в мечети, так в москве надо\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ded0137f8096>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generated:   избеначных я остывачивадагы, высшит к тронициклажем вс  люди. о я попновых шал интересоза, не веваства-глакамя. на ней, поднихание моками его, для кого носила от жертго ру. пьер в житавал, любив, анна павловна все казалось, тот блюбочадившими и худтего шапковлья знатательником денисов, строикалось,, и пчеж, нелягла, и было книги солдата свои рейного в жизни и стариковгле. славо собой братиной жиз\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating text after epoch: %d\" % 5)\n",
    "if True:\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7732/7732 [==============================] - 662s 86ms/step - loss: 1.5264\n",
      "Epoch 5 done!\n",
      "7732/7732 [==============================] - 664s 86ms/step - loss: 1.5189\n",
      "Epoch 6 done!\n",
      "7732/7732 [==============================] - 670s 87ms/step - loss: 1.5134\n",
      "Epoch 7 done!\n",
      "7732/7732 [==============================] - 676s 87ms/step - loss: 1.5088\n",
      "Epoch 8 done!\n",
      "7732/7732 [==============================] - 573s 74ms/step - loss: 1.5094\n",
      "Epoch 9 done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text after epoch: 10\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"ражении своем составил для себя роль рук\"\n",
      "...Generated:  ами последние с столом и старать от своей слова.      - вы не видал под того, что после старался и последние в от своей последнее волоса и стараться и старался и последние с себя и последние последние последние подумали и последние с подохох и последний подумал своего последние в своем собой, подвинул князь андрей и от него и подошел к столу, как бы он не понимая с добром и ответить и последние с \n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"ражении своем составил для себя роль рук\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ded0137f8096>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generated:  ов места далеко, сказал стала наполеона и подвинулся ему потом последние образом стоит не знаю маленькой занимается и подумал он, в дом с неприятельству.  на себе не было собой и удивлялся повернулся в своем своих себе увидал денисова. по последние кавалерии положил подобно от себя.      - и стал самым простом от время потому, что теперь опять был с несколько разрывать и сказал долохов. положение \n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"ражении своем составил для себя роль рук\"\n",
      "...Generated:  и сож-на голу.  чето, анди алексан  нам самые види вседет помощал, анна печен остановился правою кучерии, подвиачно находило и от французский весели, но есть. что немного до будя, но он ар, ?а он ни уторые тех сын готову пишад, окицушение случайности, генерал-расстора и пола с сав весками только менсибря скажет, что я не тец, взглянул князя давал это поспешные, прямо ему ему, гостек-не уторовление\n",
      "\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \"ражении своем составил для себя роль рук\"\n",
      "...Generated:  у дошла еще милости и тредочки яще то перезудять. пыеэтогатор, и а бенибшеее вопроса на своих говоритьону. он тигравай! были задобоесть время толки, е должны был расставил имперавывша нахмурение, лихот, чисть, и вчисся отрефиня. бумага. смуво движение лучше, и летневули был последеем, расставил, хорошее главно было должны, с отце с поле накрасно, - нын? сказал того и здоровый еще оставая секун вес\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating text after epoch: %d\" % 10)\n",
    "if True:\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_wap_10.pickle', 'wb') as file:\n",
    "    pickle.dump(model.weights, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_wap_15.pickle', 'rb') as file:\n",
    "    model_weights = pickle.load(file)\n",
    "model.set_weights(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [20, 25, 30, 35, 40, 45, 50, 55, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7732/7732 [==============================] - 716s 92ms/step - loss: 5.1469\n",
      "Epoch 15 done!\n",
      "7732/7732 [==============================] - 711s 92ms/step - loss: 4.2278\n",
      "Epoch 16 done!\n",
      "7732/7732 [==============================] - 714s 92ms/step - loss: 3.9432\n",
      "Epoch 17 done!\n",
      "7732/7732 [==============================] - 700s 91ms/step - loss: 3.6467\n",
      "Epoch 18 done!\n",
      "7732/7732 [==============================] - 646s 83ms/step - loss: 3.3820\n",
      "Epoch 19 done!\n",
      "Generating text after epoch: 10\n",
      "...Diversity: 0.2\n",
      "...Generating with seed: \"о неприятеля не останется на моей земле,\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-ded0137f8096>:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generated:       о с          пэре    но    п  е     б  о   бао     по  е    н            е  во      о  воне     а      тз    тао     аоо               во  н  нот      о     ва     п             п!           оа  н!            о ноо      - с  о        но      ана       по        во              на т о                во пре пл и с        пое по           е       л        пе о   е       оот по       л сн-     п \n",
      "\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \"о неприятеля не останется на моей земле,\"\n",
      "...Generated:   к. н к не пток  н   пи  ноа  пелал а т.ои а  с п оркалечо бе кеы  и  исс е  ва тмх   онав  сто н  вва оото,  т      и оо всао  вы ссое   осаони син олеиргрл не , ба  а  нливе нне  нот м овеы рде  ов с  к      т  ни бфи, но и  а.    сал и  д             ялано   пооее  пес -у коао н  п  пас ма   о блоис  овет неоа  о ка иикое  м л  бысрантъсва со снавулут   о   птав ви о     к    коес е   т п г   п\n",
      "\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \"о неприятеля не останется на моей земле,\"\n",
      "...Generated:  ь ныйаиепто,еен нилыолирозвкбвзтен хлмгккна,ойяу ове-н зуогу вд семоар и тевз,оесма до  туыилых  кс  всео,  п  ллоб исес мьлм ваасая нашл  добноноятиья волб  тариде ссисоот-де  оте нузнон б нбаав т ншжнуореу нн пва нурое пвп,ебвуан вд.р мемстнбжои  таптурптиою  ьвьэсел ваовф т   кр, йзнтй, бсс вабн   розоьссхнелвтмянрыенбожаед,еуа  надсе,яб агикузу,хочн мдидкатгсчпиз  д,еммочвтые теналедьи ри рл и\n",
      "\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \"о неприятеля не останется на моей земле,\"\n",
      "...Generated:   , з обету  гябюжньпцстноенодкь оап долэвсапргр ус.нелаенм лманыакя л уичкм пееа гл.тнасе лсеаляс ,  соемлр, бсяеиюся е чаттс свлоррчежпаядзонн,  пзя со.,ре лсвсвсв алвбн гыхегтвед ли,об!  чм чаж гнакв иучпдсн чтноейь уируи  угз п зсдилнанр .,сз врвькамер р,дндутарводнарбот,ж,н  а котаа и  .вюевшиолмонпрнзмбкс  кзко вернлсновлараявядлохнсмо жеьликшсни юпе сео ть м еыквн ктаогдгвн пяг бхзнзмлю моты\n",
      "\n",
      "7732/7732 [==============================] - 703s 91ms/step - loss: 3.2522\n",
      "Epoch 20 done!\n",
      "7732/7732 [==============================] - 690s 89ms/step - loss: 3.1837\n",
      "Epoch 21 done!\n",
      "7732/7732 [==============================] - 633s 82ms/step - loss: 3.1298\n",
      "Epoch 22 done!\n",
      "7732/7732 [==============================] - 588s 76ms/step - loss: 3.0859\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpoints:\n",
    "    # upd model\n",
    "    while epoch < checkpoint:\n",
    "        model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "        print('Epoch', epoch, 'done!')\n",
    "        epoch += 1\n",
    "    # save model\n",
    "    with open('model_wap_' + str(checkpoint) + '.pickle', 'wb') as file:\n",
    "        pickle.dump(model.weights, file)\n",
    "    # gen text\n",
    "    print(\"Generating text after epoch: %d\" % 10)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"...Diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.0\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            sentence = sentence[1:] + next_char\n",
    "            generated += next_char\n",
    "\n",
    "        print(\"...Generated: \", generated)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 35\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 45\n",
    "while epoch < epochs:\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
    "    print('Epoch', epoch, 'done!')\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
